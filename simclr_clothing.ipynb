{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2364\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2363\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2364\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2365\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAvailable matplotlib backends: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49menable_matplotlib(args\u001b[39m.\u001b[39;49mgui\u001b[39m.\u001b[39;49mlower() \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(args\u001b[39m.\u001b[39;49mgui, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m args\u001b[39m.\u001b[39;49mgui)\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_show_matplotlib_backend(args\u001b[39m.\u001b[39mgui, backend)\n",
            "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3513\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39menable_matplotlib\u001b[39m(\u001b[39mself\u001b[39m, gui\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3493\u001b[0m     \u001b[39m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[1;32m   3494\u001b[0m \n\u001b[1;32m   3495\u001b[0m \u001b[39m    This takes the following steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3511\u001b[0m \u001b[39m        display figures inline.\u001b[39;00m\n\u001b[1;32m   3512\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3513\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib_inline\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_inline\u001b[39;00m \u001b[39mimport\u001b[39;00m configure_inline_support\n\u001b[1;32m   3515\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m pylabtools \u001b[39mas\u001b[39;00m pt\n\u001b[1;32m   3516\u001b[0m     gui, backend \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mfind_gui_and_backend(gui, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpylab_gui_select)\n",
            "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/matplotlib_inline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_inline, config  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.6\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# noqa\u001b[39;00m\n",
            "File \u001b[0;32m~/test_env/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m colors\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_agg\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "`A Simple Framework for Contrastive Learning of Visual Representations <https://arxiv.org/abs/2002.05709>`_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import pytorch_lightning as pl\n",
        "import lightly\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import normalize\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "num_workers = 8\n",
        "batch_size = 256\n",
        "seed = 1\n",
        "max_epochs = 20\n",
        "input_size = 32\n",
        "num_ftrs = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "dataset_train_simclr = torchvision.datasets.CIFAR10(root='data/', train=True,\n",
        "                                        download=True)#, transform=transform)\n",
        "dataset_test = torchvision.datasets.CIFAR10(root='data/', train=False,\n",
        "                                       download=True)#, transform=transform)\n",
        "\n",
        "\"\"\"\n",
        "dataset_train_simclr = lightly.data.LightlyDataset(\n",
        "    input_dir=path_to_data\n",
        ")\n",
        "\n",
        "dataset_test = lightly.data.LightlyDataset(\n",
        "    input_dir=path_to_data,\n",
        "    transform=test_transforms\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup data augmentations and loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "collate_fn = lightly.data.SimCLRCollateFunction(\n",
        "    input_size=input_size,\n",
        "    vf_prob=0.5,\n",
        "    rr_prob=0.5\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "collate_fn = lightly.data.SimCLRCollateFunction(\n",
        "    input_size=input_size,\n",
        "    vf_prob=0.5,\n",
        "    rr_prob=0.5,\n",
        "    cj_prob=0.0,\n",
        "    random_gray_scale=0.0\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# We create a torchvision transformation for embedding the dataset after \n",
        "# training\n",
        "test_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((input_size, input_size)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=lightly.data.collate.imagenet_normalize['mean'],\n",
        "        std=lightly.data.collate.imagenet_normalize['std'],\n",
        "    )\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "dataloader_train_simclr = torch.utils.data.DataLoader(\n",
        "    dataset_train_simclr,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "dataset_train_simclr[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the SimCLR Model\n",
        "ResNet-18 backbone from Torchvision. \n",
        "Lightly provides implementations of the SimCLR projection head and loss function in the `SimCLRProjectionHead` and `NTXentLoss` classes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from lightly.models.modules.heads import SimCLRProjectionHead\n",
        "from lightly.loss import NTXentLoss\n",
        "\n",
        "\n",
        "class SimCLRModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # create a ResNet backbone, adapt it to cifar and remove the classification head\n",
        "        resnet = torchvision.models.resnet18(pretrained=False, num_classes=10)\n",
        "        resnet.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        resnet.maxpool = nn.Identity()\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "        hidden_dim = resnet.fc.in_features\n",
        "        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, 128)\n",
        "\n",
        "        self.criterion = NTXentLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(h)\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        (x0, x1), _, _ = batch\n",
        "        z0 = self.forward(x0)\n",
        "        z1 = self.forward(x1)\n",
        "        loss = self.criterion(z0, z1)\n",
        "        self.log(\"train_loss_ssl\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.SGD(\n",
        "            self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optim, max_epochs\n",
        "        )\n",
        "        return [optim], [scheduler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "gpus = 1 if torch.cuda.is_available() else 0\n",
        "\n",
        "model = SimCLRModel()\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=max_epochs, gpus=gpus#, progress_bar_refresh_rate=100\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#train model\n",
        "trainer.fit(model, dataloader_train_simclr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#save backbone\n",
        "\n",
        "pretrained_resnet_backbone = model.backbone\n",
        "\n",
        "state_dict = {\n",
        "    'resnet18_parameters': pretrained_resnet_backbone.state_dict()\n",
        "}\n",
        "torch.save(state_dict, 'models/pretrained_resnet_backbone.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# load the model in a new file for inference\n",
        "resnet18_new = torchvision.models.resnet18()\n",
        "\n",
        "# note that we need to create exactly the same backbone in order to load the weights\n",
        "backbone_new = nn.Sequential(*list(resnet18_new.children())[:-1])\n",
        "\n",
        "ckpt = torch.load('models/model_color.pth')\n",
        "backbone_new.load_state_dict(ckpt['resnet18_parameters'])\n",
        "\n",
        "model.backbone = backbone_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we create a helper function to generate embeddings\n",
        "from our test images using the model we just trained.\n",
        "Note that only the backbone is needed to generate embeddings,\n",
        "the projection head is only required for the training.\n",
        "Make sure to put the model into eval mode for this part!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def generate_embeddings(model, dataloader):\n",
        "    \"\"\"Generates representations for all images in the dataloader with\n",
        "    the given model\n",
        "    \"\"\"\n",
        "\n",
        "    embeddings = []\n",
        "    filenames = []\n",
        "    with torch.no_grad():\n",
        "        for img, label, fnames in dataloader:\n",
        "            img = img.to(model.device)\n",
        "            emb = model.backbone(img).flatten(start_dim=1)\n",
        "            embeddings.append(emb)\n",
        "            filenames.extend(fnames)\n",
        "\n",
        "    embeddings = torch.cat(embeddings, 0)\n",
        "    embeddings = normalize(embeddings)\n",
        "    return embeddings, filenames\n",
        "\n",
        "\n",
        "model.eval()\n",
        "embeddings, filenames = generate_embeddings(model, dataloader_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Nearest Neighbors\n",
        " Let's look at the trained embedding and visualize the nearest neighbors for \n",
        " a few random samples.\n",
        "\n",
        " We create some helper functions to simplify the work\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def get_image_as_np_array(filename: str):\n",
        "    \"\"\"Returns an image as an numpy array\n",
        "    \"\"\"\n",
        "    img = Image.open(filename)\n",
        "    return np.asarray(img)\n",
        "\n",
        "\n",
        "def plot_knn_examples(embeddings, filenames, n_neighbors=3, num_examples=6):\n",
        "    \"\"\"Plots multiple rows of random images with their nearest neighbors\n",
        "    \"\"\"\n",
        "    # lets look at the nearest neighbors for some samples\n",
        "    # we use the sklearn library\n",
        "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(embeddings)\n",
        "    distances, indices = nbrs.kneighbors(embeddings)\n",
        "\n",
        "    # get 5 random samples\n",
        "    samples_idx = np.random.choice(len(indices), size=num_examples, replace=False)\n",
        "\n",
        "    # loop through our randomly picked samples\n",
        "    for idx in samples_idx:\n",
        "        fig = plt.figure()\n",
        "        # loop through their nearest neighbors\n",
        "        for plot_x_offset, neighbor_idx in enumerate(indices[idx]):\n",
        "            # add the subplot\n",
        "            ax = fig.add_subplot(1, len(indices[idx]), plot_x_offset + 1)\n",
        "            # get the correponding filename for the current index\n",
        "            fname = os.path.join(path_to_data, filenames[neighbor_idx])\n",
        "            # plot the image\n",
        "            plt.imshow(get_image_as_np_array(fname))\n",
        "            # set the title to the distance of the neighbor\n",
        "            ax.set_title(f'd={distances[idx][plot_x_offset]:.3f}')\n",
        "            # let's disable the axis\n",
        "            plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's do the plot of the images. The leftmost image is the query image whereas\n",
        "the ones next to it on the same row are the nearest neighbors.\n",
        "In the title we see the distance of the neigbor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "plot_knn_examples(embeddings, filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open image from Url\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"https://www.helikon-tex.com/media/catalog/product/cache/4/image/9df78eab33525d08d6e5fb8d27136e95/s/p/sp-pgm-dc-11.jpg\"\n",
        "\n",
        "\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def url_nearest_images(model, url, n_neighbors=5):\n",
        "    \"\"\"Generates representations for a given image\n",
        "    \"\"\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    print(\"ORIGINAL IMAGE AND NEIGHBORS IN DATABASE\")\n",
        "    plt.imshow(img)\n",
        "\n",
        "    img = test_transforms(img)\n",
        "    img = torch.unsqueeze(img, 0)\n",
        "\n",
        "    img = img.to(model.device)\n",
        "    emb = model.backbone(img)\n",
        "\n",
        "    emb = emb.flatten(start_dim=1)\n",
        "\n",
        "    emb = emb.detach().numpy()\n",
        "\n",
        "    nbrs = NearestNeighbors(n_neighbors=n_neighbors).fit(embeddings)\n",
        "    distances, indices = nbrs.kneighbors(emb)\n",
        "\n",
        "\n",
        "\n",
        "    # loop through our randomly picked samples\n",
        "    for idx in range(len(emb)):\n",
        "        fig = plt.figure()\n",
        "        # loop through their nearest neighbors\n",
        "        for plot_x_offset, neighbor_idx in enumerate(indices[idx]):\n",
        "            # add the subplot\n",
        "            ax = fig.add_subplot(1, len(indices[idx]), plot_x_offset + 1)\n",
        "            # get the correponding filename for the current index\n",
        "            fname = os.path.join(path_to_data, filenames[neighbor_idx])\n",
        "            # plot the image\n",
        "            plt.imshow(get_image_as_np_array(fname))\n",
        "            # set the title to the distance of the neighbor\n",
        "            ax.set_title(f'd={distances[idx][plot_x_offset]:.3f}')\n",
        "            # let's disable the axis\n",
        "            plt.axis('off')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.6 (conda)' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -p /home/jovyan/test_env ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "url = \"https://img.kytary.com/eshop_de/velky_v2/na/637329305569630000/bd547319/64771944/ant-tshirt-ant-blu-l.jpg\"\n",
        "url_nearest_images(model, url)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 (conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "097b7033baff6ef61c19d5e3b26d00f2edd9fddb86c25af544d86fb0636b8d9f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
